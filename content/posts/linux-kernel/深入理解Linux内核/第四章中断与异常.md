---
title: "第四章中断与异常"
date: 2022-06-28T21:34:22+08:00
topics: "linux-kernel"
draft: true
---

> 笔记不能再这样记了，不是不行而是太费事件
> 应该是用自己的语言总结归纳，完全过程性的摘录没有意义（Marginote的作用）
> 处理概念性的知识，一个功能只需要告诉我这么做的目的是什么，要求什么功能，代码自会告诉我如何实现的，而不是完全的去记忆代码的过程。



# 中断与异常基础

中断即外部IO设备或定时器，发出的中断。

异常即各种指令执行时产生的内部CPU中断，通常由程序的执行错误产生，某些异常在被中断处理程序执行后，还会通过UNIX信号的方式发送给当前的进程（即引发异常者），而有些异常则由内核负责处理，比如缺页异常由内核执行相关的调页程序。

> 个人而言更喜欢称为外部中断与内部中断。毕竟这里说的异常也用来实现系统调用，叫异常反而不太好。
> 外部中断也可以叫异步中断，因为IO设备随时可能发出
> 内部中断也叫同步中断，因为是在CPU执行指令结束后才发出

> 但下文中还是使用中断和异常的概念，中断就是指外部中断，异常指内部中断

每个中断和异常由0-255之间的一个数来表示，Intel把这个8位的无符号数称为**中断向量**。

异常和不可屏蔽中断的中断向量是固定的由0-31表示

## || 中断与异常的分类

### 中断分类

* 可屏蔽中断，IO设备发出的中断都是可屏蔽中断
* 不可屏蔽中断，只有几个危机事件（如硬件故障）才引起该异常

### 异常分类

根据`eip`中保存中值的情况，可以分为以下三类：

1. 故障（fault），`eip`中保存着引发故障的指令地址，通常在该异常处理程序结束后，从该指令（引发故障）重新执行。比如缺页异常

2. 陷阱（trap），`eip`中保存的是引发异常的指令的下一条指令地址。异常处理程序结束后从下一条指令开始执行。

3. 异常终止（abort），发生严重错误，不能在`eip`中保存引发异常的指令确切地址。异常终止处理程序除了强制终止受影响的进程没有其他选择。

4. 可编程异常，由用户编程引发，比如int、int3指令或者into、bound指令检测不为真时。**CPU控制单元把可编程异常当作陷阱来处理**，可编程异常通常用来执行系统调用或者调试程序。其也叫做软中断。

> 可编程异常可以认为是一种中断类型码（向量）由用户给出的陷阱。


## || 80x86产生的异常

## || 中断请求（IRQ）与中断控制器

### 传统可编程中断控制器（传统PIC）

### 高级可编程中断控制器（APIC）

## || 中断向量
p157

Linux中仅仅使用`irq`号来做数组索引，从0开始比较方便，实际就是一个中断向量，然后中断向量-32得到`irq`索引号，~~实际硬件操作某个IRQ还要加回去的。~~

## || 中断（异常）描述符表

## || 中断和异常的硬件处理过程
假定内核已经完成了初始化。

当执行一条指令后，`cs`和`eip`会指向下一条指令的地址。在执行下一条指令之前，CPU会检查当前指令执行期间是否产生了中断和异常，若产生了执行以下操作：

1. 确定中断或者异常向量`i`，[0, 255]
2. 根据`idtr`读取IDT中索引为`i`的描述符（假定此时只包含中断门和陷阱们的描述符）
3. 根据IDT表项的段选择符和`gdtr`读取GDT中相应的段描述符
> 这个段选择符一般来说是__kernel_cs，即内核代码段，因为中断和异常处理程序应该都在内核中
4. 判断中断和异常的特权级。对于**编程异常**，需要CPL小于等于IDT表项的DPL，用来避免用户访问一些特殊的中断或者陷阱门，否则产生一个`General Protection`异常。对于中断，需要CPL大于等于GDT表项的DPL。（**原因未知**，就Linux而言所有中断处理程序都在内核中，对应的DPL=0，这个检查没有意义）
> 对于用户可访问的异常处理程序可以将其IDT表项的DPL设为3
> 用户不可访问的中断或者异常处理程序，IDT表项DPL设为0
5. 检查是否发生特权级变化，若变化需要执行以下步骤切换栈。
> 一般来说都是从CPL=3切换到CPL=0，即切换到内核栈

* 读`tr`寄存器，访问TSS段内容
* 用新特权级相关的栈段和栈顶地址装载到`ss`和`esp`寄存器
* 在新栈中保存装载之前`ss`和`esp`的值
> cpu可能有其他的不可编程寄存器保存`ss`和`esp`的副本，这样才能在`ss`和`esp`被覆盖后，保存原来的值
> 新的`ss`应该是`__kernel_ds`

6. 如果故障异常，需要把异常的指令地址装载到`cs`和`eip`寄存器中（替换调原来的下一指令地址），以便之后重新执行
7. 把`eflags`、`cs`、`eip`寄存器推入栈中（新栈）
> 入栈之后必要时还应该清除`eflags`的`IF`和`TF`标志
8. 如果异常产生了硬件出错码，还需要把该值也推入栈中
9. 将IDT中对应表项的段选择符和偏移量装载到`cs`和`eip`中，即转到中断处理程序执行

当中断和异常处理结束时，处理程序需要执行`iret`指令返回断点继续执行:
1. 从栈中恢复`eflags`、`cs`、`eip`的值，如果之前推入了硬件错误码，则需要由中断处理程序在执行`iret`之前手动出栈
2. 检查处理程序的CPL和`cs`中的CPL，若相同则`iret`指令执行完毕，若不相同还需要执行下面的步骤恢复原来的栈
3. 从栈中恢复`ss`和`esp`，以返回原来的栈
4. 检查`ds`、`es`、`fs`、`gs`段寄存器，若存在某个段选择符对应的段描述符的DPL小于CPL，还需要清除该寄存器，防止用户访问内核数据。

## || 中断描述符表-基础初始化

# Linux异常处理


# Linux中断处理

中断是由外部设备发来的，虽然借助于当前进程的内核栈运行，但和当前进程完全无关的。所以中断到来了先当前进程发送信号是没有意义的，并且一般也需要中断处理程序和设备做一些交互（比如获取数据）。

中断的处理过程依赖于中断类型，主要讨论三类

* I/O中断，相应的中断处理程序必须查询设备以确定合适的操作过程
* 时钟中断，在第六章介绍，这些中断大部分是作为IO中断处理的
* 处理器间中断

## || I/O中断处理

### IRQ号共享

由于设备可能共享IRQ线（此时也共享IRQ号和中断向量），所以通常一个中断处理程序（对应一个中断向量）必须要有足够的灵活性，可以同时为多个设备提供服务，这里通常有两种方案。

* 此时无法依靠中断向量区分是哪个设备发出的IRQ，在对应的中断处理程序中，将会执行一个中断服务例程（ISR）链表，每个中断服务例程对应一个设备。
* IRQ动态分配，即只有在最后一刻即需要使用该设备时，才将其ISR插入到对应的ISR链表中，执行结束后将ISR从链表中删除。
> 动态分配示例见**IRQ动态分配**一节

> 每个IRQ（号/线）其实就对应一个中断向量，Linux内核中默认IRQ号+32等于向量。所以`中断向量-32`就定位到IRQ号了
> 

### 中断处理程序拆分-上下半部

中断处理程序完成的工作可以分为紧急的和可推迟的，为了保证每个中断的紧急部分能够被内核快速响应，同时保证PCI能被快速应答（应答了才能处理其他的IRQ）提高吞吐率，所以将中断处理程序拆分为上下半部，上半部在关中断时执行紧急操作，下半部开中断可被抢占延迟执行。

* 这些紧急的任务因为要快速的完成，所以必须要在禁止本地中断的情况下执行。比如网卡通知数据到来了，由于网卡的缓存有限必须快速将数据拷贝到系统内存中避免网卡缓存溢出导致丢包。
* 非紧急任务就可以开中断延迟执行。比如将网卡拷贝到系统内存的数据，拷贝到具体的进程空间

Linux提供了两种下半部延迟执行的功能：
1. 软中断
2. 工作队列

> 从这里开始，**中断处理程序**指整个上下半部的程序，**中断服务例程（ISR）**指上半部中处理例程

### 中断涉及的数据结构

> 具体每个类型的字段见p158，这只介绍常用字段

**IRQ描述符-`irq_desc_t`**
每个中断向量（IRQ号）都有自己的描述符，类型为`irq_desc_t`，存放在数组`irq_desc`中。
`irq_desc_t`字段

* `handler`，指向抽象PIC对象（`hw_irq_controller`类型），各类PIC芯片的通用抽象
* `action`，指向`irqaction`链表的第一个元素，每个`irqarction`对应一个ISR
* `status`，IRQ线的状态，只和上半部中断处理程序有关，常用标志见下表
* `depth`，IRQ被禁止的次数，为0则表示未被禁止
* `lock`，该类型实例的自旋锁，用在SMP中
* `irq_count`，收到的IRQ数量
* `irq_unhandled`，收到的无法处理的IRQ数量

注意`status`字段基本只与上半部中断处理程序相关
status标志|含义
:-:|:--
IRQ_DISABLED|该IRQ线已被禁用
IRQ_INPROGRESS|上半部中断处理程序正在运行
IRQ_PENDING|IRQ已向PIC应答，但还未执行

> 这里每个标志只占一位，所以`status`可以同时设置多个标志。如：`IRQ_PROGESS=1` `IRQ_DISABLED=2` `IRQ_PENDING=4`始终是2的幂次

当收到一个IRQ之后，如果当前的中断处理程序一个ISR也没有，或者ISR链表中没有对应的ISR，那么这个IRQ是无法处理的，会被计数到`irq_unhandled`。

当`irq_unhandled`在`irq_count`中所占比例非常大时，内核才会认为链接到该IRQ的设备出错，考虑禁用该IRQ线。

`depth`字段和`status`的`IRQ_DISABLE`表示IRQ线的禁用。主要配合`disable_irq_nosync()`和`enable_irq()`来使用。每次`disable`都增加`depth`，每次`enable`都递减`depth`，只有在第一`disable`时（即`depth=0`）才实际设置`IRQ_DISABLE`和以及通知PIC电路，`enable`同理只有最后一次即`depth`也为0才设置。

`depth`可以避免多次设置`status`和通知硬件，同时也保证多处理器系统中必须所有的`disable`都`enable`了才可以实际的激活IRQ（因为IRQ线是多处理器共用的）

> 根据源码`linux-2.6.12/kernel/irq/manage.c:void enable_irq(unsigned int irq)`在这里执行的**挽救丢失的中断**

Linux中支持多种PIC电路，为了给驱动程序提供透明PIC，Linux抽象出了7个标准方法作为PIC的控制接口。即`hw_irq_controller`类型的字段`handler`
```c
static struct hw_interrupt_type i8259A_irq_type = {
	.typename = "XT-PIC",
	.startup = startup_8259A_irq,
	.shutdown = shutdown_8259A_irq,
	.enable = enable_8259A_irq,
	.disable = disable_8259A_irq,
	.ack = mask_and_ack_8259A,
	.end = end_8259A_irq,
};
```

> `hw_interrupt_type`和`hw_irq_controller`同义


**`irqaction`描述符**
字段名|说明
:-:|:--
handler|指向中断处理例程（ISR）
flags|描述设备与IRQ的关系，如是否允许IRQ共享
next|指向下一个`irqaction`
dev_id|设备id

flags标志|说明
:-:|:--
SA_INTERRUPT|该设备ISR必须以禁止中断执行
SA_SHIRQ|允许其他设备共享IRQ
SA_SAMPLE_RANDOM|设备可以作为随机事件发生源

**`irq_stat`数组**
该数组含有`NR_CPUS`个元素，也就是CPU的个数，每个元素类型为`irq_cpustat_t`，该类型字段如下：

字段名|描述
:-:|:--
`__softirq_pending`|处于pending状态即已激活的软中断掩码，每一位二进制1表示一个软中断
`__nmi_count`|非屏蔽中断数量
`apic_timer_irqs`|本地APIC时钟中断次数


### IRQ在对称多处理器（SMP）上的分发
对称则意为着所有的CPU都是应一视同仁，没有什么主从之分。前面已经说过`APIC`可以被配置为根据优先级自己动态分发IRQ。

系统启动时，通过`setup_IO_APIC()`函数初始化了24项I/O-APIC的重定向表，配置根据**最低优先级**模式分发IRQ。

同时通过`setup_local_APIC()`初始化本地APIC，把每个CPU的任务优先寄存器都设置为优先级最低的同一固定值，之后Linux不会再修改这个值，这意味着I/O-APIC会根据每个本地APIC的仲裁寄存器，自动循环给每个CPU分发IRQ。

但可惜的是，某些硬件平台不能以公平的方式分发IRQ。此时Linux通过使用名为`kirqd`的特殊内核进程来手动调整。`kirqd`周期性执行`do_irq_balance`函数，跟踪最近的每个CPU接收到的中断次数，当CPU之间的IRQ负载非常不平衡时，`kirqd`通过重设IO-APIC的重定向表来重新平衡负载。这通过`set_ioapic_affinity_irq`实现，可以将某个IRQ号（向量）定向到固定的CPU。
> 系统管理员也可以通过`/proc/irq/n/smp_affinity`来手动修改CPU掩码来指定某个CPU对`n`号IRQ的亲和力

### 多种类型的内核栈（4K栈）

对于8K的内核栈，不管是中断、异常、软中断（可延迟函数）都使用这一个内核栈作为中断上下文。

而对于4KB的内核栈，该栈只用于执行异常。中断和软中断使用每个CPU所独有的4KB栈。

`hardirq_stack`数组中存放了类型为`irq_ctx`的`NR_CPUS`个中断请求栈地址，`softirq_stack`则存放`NR_CPUS`个软中断请求栈的地址。每个栈和内核栈的结构相同，栈从高到低生长，页面下面仍然放置一个`thread_info`

### 中断处理总体过程

在系统初始化期间，`init_IRQ`函数重新更新了IDT表项（最初由`setup_idt()`设置为`ignor_int`）
```c
for(int i = 0; i < NR_IRQS; i++){
	if (i + 32 != 128)
		set_intr_gate(i+32, interrupt[i]);
}
```
`interrupt[i]`就是对应IRQ号`i`的中断处理程序的入口地址，其实每个`interrupt[i]`的汇编代码都是相同，只是推入栈中的IRQ号不同。
> `interrupt`数组是在`arch/i386/kernel/entry.s`中使用汇编语言构造的
> 数组大小由`NR_IRQS`产生，老式PIC产生值为16，IO-APIC产生值224（即256-32）
```asm
pushl $n-256
jmp common_interrupt

common_interrupt:
	SAVE_ALL
	movl %esp, %eax
	call do_IRQ
	jmp ret_from_intr

```
这里将IRQ号`n-256`的4B补码推入了内核栈中作为`common_interrupt`的隐式参数（`do_IRQ`中使用），~~内核用负数表示所有中断，正数表示系统调用，见第十章）~~
`movl %esp %eax`作为`pt_regs*`指针参数传递到`do_IRQ`函数，`pt_reg`结构包含了所有推入内核栈中寄存器的值和IRQ号，其中`orig_eax`字段的偏移量就对应的`$n-256`
> `pt_regs`的定义见`include/asm-i386/ptrace.h`

其中`SAVE_ALL`宏展开后如下
```c
#define SAVE_ALL \
	cld; \
	pushl %es; \
	pushl %ds; \
	pushl %eax; \
	pushl %ebp; \
	pushl %edi; \
	pushl %esi; \
	pushl %edx; \
	pushl %ecx; \
	pushl %ebx; \
	movl $(__USER_DS), %edx; \
	movl %edx, %ds; \
	movl %edx, %es;
```
清`DF`方向标志，保护现场，设置栈段。

`do_IRQ`就是包含了整个上下半部的中断处理程序。

`do_IRQ`主要执行以下操作：
1. 执行`irq_enter()`宏，增加表示中断处理程序嵌套层数的计数字段。即`thread_info->preempt_count`字段
2. 如果内核栈为4K则需要切换到本地CPU的用于硬件中断的专用栈
    * 比较`current_thread_info()`获取到的当前栈地址和`hardirq_stack[smp_processor_id]`，若不相同则需要切换到`hardirq_stack[smp_processor_id]`表示的栈，相同则表示是嵌套中断已经切换过了
    * 保存当前的进程描述指针`current()->task`到硬件专用栈的`thread_info`的`task`字段中，以便`current()`宏能获取到当前进程描述符
    * 保存`esp`到本地CPU的`irq_ctx`的`threadinfo->previous_esp`字段中（~~仅当为内核oop准备函数调用跟踪时使用该字段~~）
    * 切换到CPU硬件中断栈，即将`hardirq_stack[cur_cpu_id]+4096`写入`esp`，原`esp`保存到`ebx`中

3. 执行`__do_IRQ`函数，该函数即是中断处理程序的上半部
4. 如果在2步执行了内核栈切换，则此时需要将`ebx`存储的原来栈顶装载到`esp`即切换回原来的栈。
5. 执行`irq_exit()`宏，该宏递减`thread_info->preempt_count`字段，并检查是否有可执行的可延迟函数（软中断函数）

### 中断处理过程`__do_IRQ()`-上半部

`__do_IRQ`接受IRQ号（`eax`传递）和指向`pt_regs`的指针（`edx`传递）。

该函数的一个设计目标，是在任何情况下（包括硬件出错）都要保证**同IRQ号**的ISR必须**串行**执行，这样ISR可以不必具有可重入性，简化驱动程序的设计和内核结构。
> 作为紧急的上半部，需要内核快速响应中断，所以最好关中断，保证不被打断能快速执行。同时为了内核和驱动程序设计的简洁性，对于同类ISR必须保证其串行执行。

要保证串行执行，需要考虑两种情况，多CPU上的串行执行，单CPU上的串行执行。
* 单CPU的串行执行，可以通过关CPU的IF标志，禁止所有的中断来实现。也可以在开中断的情况下，禁止当前IRQ线或者通过设置标志来实现（之后代码中会体现）。总之无论如何要保证同类型ISR串行。
* 多CPU上的串行，使用自旋锁实现和状态标志实现（具体见下列代码）

```c
spin_lock(&(irq_desc[irq].lock));
irq_desc[irq].handler->ack(irq);
irq_desc[irq].status &= ~(IRO_REPLAY | IRO_WAITING);
irq_desc[irq].status |= IRQ_PENDING;
if(!(irq_desc[irq].status & (IRQ_DISABLED｜IRQ_INPROGRESS)) && irq_desc[irq].action){
    irq_desc[irq].status |= IRO_INPROGRESS;
    do{
        irq_desc[irq].status&=~IRQ_PENDING;
        spin_unlock(&(irq_desc[irq].lock));
        handle_IRQ_event(irq, regs, irq_desc[irq].action);
        spin_lock(&(irq_desc[irq].lock));
    }while(irq_desc[irg].status & IRQ_PENDING);

    irq_desc[irq].status&=~IRQ_INPROGRESs;
}

irq_desc[irq].handler->end(irq);
spin_unlock(&(irq_desc[irq].lock));
```

对于同时出现在多个CPU上的同类型IRQ，首先自旋锁会保证`irq_desc[irq]`的竞争条件不会出现数据错误，同时会保证一个CPU（A）进入`if`块内并设置`IRQ_INPROGRESS`标志，然后在消除`IRQ_PENDING`后才会释放锁并执行ISR。之后另一个CPU（B）立刻获得锁，会在设置完`IRQ_PENDING`后由于`IRQ_INPROGESS`存在而直接退出（此时A CPU由于无法获得锁，即使ISR执行完了不可能消除`IRQ_INPROGESS`标志）。然后A CPU获得锁，while语句发现`IRQ_PENDING`被设置了，则继续执行，此时由于刚才ISR访问过的数据仍在cache中，对系统性能是有益的。

> 关于自旋锁可以这么理解：其实为了保证多CPU之间的并行，其实就是使用简单的标志就行了`IRQ_INPROGRESS`，只要该标志被设置就表示有CPU在执行必须跳过，但是我们也知道这种标志变量就是临界资源，需要锁保护

对于单CPU，不管是关中断还是禁用IRQ都保证了同类IRQ的串行执行。即使某个ISR允许被中断，开中断了，但此时IRQ线被禁用也可以保证串行，即使IRQ线没有被禁用，`IRQ_INPROGESS`标志被设置了也可以保证串行执行。


### 处理中断服务例程（ISR）

`__do_IRQ`中执行的`handle_IRQ_event()`函数，负责处理整个`ISR`链表。

值得注意的是，在该函数中检查`irqaction->flags`，若未设置`SA_INTERRUPT`则需要执行`cli`开中断，执行结束后再关闭。

具体的某个ISR只有在成功处理中断后，才返回1，可以据此更新`irq_desc_t->irq_count,irq_unhandled`字段，统计IRQ情况。


### 挽救丢失的中断

这里是说的一个极小概率的特殊情形。

首先明确一个前提，当`IRQ_DISABLED`被设置时，物理芯片PIC的对应IRQ管脚也应该是禁用的。如果一切正常，是不应该产生中断请求的，自然也没`__do_IRQ`什么事。

但总有意外发生，首先，由于硬件问题它仍然可能会产生所谓的伪中断，此时由于检测到来`IRQ_DISABLED`自然不会执行，但`IRQ_PENDING`还是被设置了。

其次就是我们这里的特殊情况，假设此时还没人禁用IRQ，那么在多处理器中一个CPU正常收到了该IRQ，但是在它还没处理完时比如还没`ack`或者刚设置完`IRQ_PENDDING`但还没执行，另一个CPU不知咋的禁用了该IRQ也设置了`IRQ_DISABLE`，此时出现了一个逻辑问题，即在禁用IRQ线之前收到的IRQ被确认了但是ISR没有被执行。
> 这种情况是有可能的比如该CPU还在执行`do_IRQ`里的内容，此时还没执行到`__do_IRQ`还没有给`irq_desc`上锁，那么另一个CPU的确有执行`disable_irq_nosync`的可能，尽管该函数执行时也需要获得锁

所以在`enable_irq()`函数中，启用IRQ时，还要检查是否`IRQ_PENDING`标志存在，若存在则表示有丢失的IRQ，需要强制硬件再发送一次IRQ，等价代码如下：
```c
spin_lock....
if(...){
	irq_desc[irq].status &= ~IRA_DISABLED;
	if(irq_desc[irq].status & (IRQ_PENDING|IRQ_REPLAY) == IRQ_PENDING){
		irq_desc[irq].status |= IRQ_REPLAY;
		hw_resend_irq(irq_desc[irq].handler, irq);
	}
}
spin_unlock....
```
其中`IRQ_REPLAY`是用来保证丢失的IRQ只产生一次，在其被实际执行时被清除（`__do_IRQ`中）

### IRQ线动态分配

如前**IRQ号共享**所言，推迟到设备的实际使用时，才将其ISR插入到相应的IRQ的ISR链表中。

比如此时想访问一个软盘，软盘驱动程序收到该请求后，首先应该做的就是分配一个IRQ（即插入ISR链表中）
1. 首先执行`request_irq(6, floppy_intr, SA_INTERRUPT|SA_SAMPLE_RANDOM, "floppy", NULL)`，该函数创建一个`irqaction`并用参数初始化，比如这里`floppy_intr`表示软盘ISR地址，`flags`设置为`SA_INTERRUPT|SA_SAMPLE_RANIXM`表示该ISR执行时必须关中断，该IRQ的产生可以作为随机事件源。`NULL`表示没有使用`dev_id`
2. 然后调用`setup_irq()`将该`irqaction`插入到具体的ISR链表（即`irq_desc`数组中的`action`链表），`setup_irq()`插入时需要执行如下步骤：
    * 如果该`irq_desc[irq]`的`action`为空直接插入，如果存在则需要检查新插入的`irqaction`和已在链表中的的`irqaction`是否均设置了`SA_SHIRQ`，如果没设置表示有设备无法共享IRQ，则插入失败。
    * 如果没有其他设备和其共享IRQ，也就是只有新插入的ISR，还需要重新设置`irq_desc[irq]->status`，比如清除`SA_DISABLED`、`SA_INPROGESS`等标志

## || 软中断及tasklet - 中断处理下半部

> 这里的软中断不是编程异常的别称，而是从中断处理程序中抽出的非紧急处理部分及所谓的可延迟函数

软中断即所谓的中断处理程序的下半部，是从一般中断处理程序中抽出的可延迟执行（开中断）的部分，这让内核对中断的响应时间更短（只需执行必要紧急的ISR）。

tasklet是基于软中断实现的。软中断时编译时静态分配的，即便是同一类型的软中断也可以并发的运行在多CPU上，所以软中断函数必须是可重入的需要使用自旋锁保护数据结构。tasklet则不必关心，CPU对tasklet执行严格的控制，保证**同类型**tasklet的串行执行，不同类型的仍然可以并行执行。tasklet的串行化执行，使tasklet函数不必是可重入的，减少了驱动程序开发的工作量。

可延迟函数可以执行以下四种操作：
1. 初始化，创建一个新的可延迟函数，这个操作通常在内核初始化或者加载模块时执行
2. 激活，标记一个可延迟函数为激活（pending）状态，在下一次可延迟函数调度时被执行。
3. 屏蔽，有选择的屏蔽一个可延迟函数，即使其被激活内核也不执行它
4. 执行，执行所有同类型激活的可延迟函数

> 书中翻译`pending`为挂起，和传统OS教材的挂起概念冲突了，OS教材上的挂起指暂停执行，而不是激活，所以之后一律使用激活态或者pending态

激活和执行不知为何总是绑定在一起的，给定CPU上激活了，则其执行也必然在该CPU。这样做对系统性能没有明显的好处。
> 因为，虽然软中断列表`softirq_vec`是多CPU共享的，但激活只是设置了本地CPU的`__softirq_pending`，和其他CPU无关。只有在该CPU上的`__do_softirq`才能检测到这个激活

### 软中断

Linux2.6中使用有限个软中断：
软中断|下标（优先级）|说明
:-:|:-:|:--
HI_SOFTIRQ|0|高优先级tasklet
TIMER_SOFTIRQ|1|时钟中断相关的tasklet
NET_TX_SOFTIRQ|2|把数据包传递到网卡的软中断
NET_RX_SOFTIRQ|3|从网卡接收数据
SCSI_SOFTIRQ|4|SCSI命令后台中断处理
TASKLET_SOFTIRQ|5|常规tasklet

**软中断涉及的数据结构**

软中断涉及的主要数据结构是，包含32个元素类型为`softirq_action`的数组`softirq_vec`。该数组中只有前6个被有效使用，也就是前面定义的6种类型的软中断，下标即表示其执行顺序，也就表示了优先级。`softirq_action`只有两个字段，`action`指向软中断函数地址，`data`指定软中断函数可能使用的数据地址
> 可以看到每个类型软中断只能对应一个函数

其次软中断也使用了`current_thread_info()->preempt_count`字段，该字段分成几个计数器如下：
位|描述
:-:|:--
0-7|内核抢占计数器
8-15|软中断计数器
16-27|硬中断计数器
28|PREEMPT_ACTIVE标志

> 这里所谓的硬中断指的中断的上半部，没有包含软中断

> 这里无论硬中断计数器还是软中断计数器作用都一致，一个由于ISR可能开中断执行，一个由于可延迟函数可开中断执行，故这些计数器都用来禁用对应中断保持在本地CPU上的串行化的

第一个字段其实就是表示内核抢占的次数，~~但在内核抢占时会禁用内核抢占~~，所以也是禁用的次数。当其为0时表示没有抢占也没有禁用，此时表示允许内核抢占。这将在第五章介绍。

第二个字段表示软中断禁用的程度

第三个字段表示硬中断（上半部）嵌套次数，`do_IRQ`中执行的`irq_enter()`宏负责递增，`irq_exit()`宏负责递减。

`in_interrupt()`宏会检查`current_thread_info()->preempt_count`中的硬中断和软中断计数器值，只要其中有一个不为0，则`in_interrupt`返回非0值即表示在中断中。故当`in_interrupt()`返回非0时，表示此时抢占了硬中断或者抢占了软中断。
> 抢占硬中断只有可能是某个ISR允许开中断执行时抢占的

最后一个字段是在之前中断涉及的数据结构介绍的`irq_stat`数组 该数组含有NR_CPUS个元素，也就是CPU的个数，每个元素类型为`irq_cpustat_t`，该类型字段如下：
字段名|描述
:-:|:--
`__softirq_pending`|处于pending状态即已激活的软中断掩码，每一位二进制1表示一个软中断
`__nmi_count`|非屏蔽中断数量
`apic_timer_irqs`|本地APIC时钟中断次数

主要使用的是每个CPU对应的`__softirq_pending`字段，其中32位每位对应一个类型的软中断是否激活。

**操作软中断**

* `open_irq()`初始化软中断，有三个参数软中断下标、软中断函数地址、软中断函数使用的数据地址。其操作`softirq_vec`中的对应下标元素。
* `raise_softirq()`激活软中断，它接收`nr`为软中断下标。其执行如下操作
	1. `local_irq_save`保存`eflags`寄存器，然后`sti`关中断
	2. 设置本地CPU的`__softirq_pending`字段中的对应位为1，激活该软中断。
	3. 如果`in_interrupt`宏产生1，则跳转到第5步。
	4. 否则，在需要时调用`wakeup_softirq()`唤醒本地CPU的`ksoftirqd`内核线程。
	5. `local_irq_restore`恢复`eflags`
> 只激活到本地CPU上，核心操作就是该`__softirq_pending`，关中断其实就是为了保证数据的竞争

> `rais_softirq`可能在某个ISR中被执行即此时在中断上下文中，也可能是用户请求某个驱动程序而执行此时不在中断中
* `do_softirq`，软中断处理程序 p178
* `__do_softirq`
> `__do_softirq`的原则也是要保证在单CPU上保持串行执行，多CPU之间可以并行执行
> 执行软中断不是一次执行某一个类型

**软中断被执行的时机**

* `do_IRQ`中的`irq_exit()`中
* 内核线程`ksoftirqd/n`被唤醒时
* `smp_apic_timer_interrupt`处理完时钟中断时
* CPU处理完被`CALL_FUNCTION_VECTOR`触发的处理器间中断时

**ksoftirqd内核线程**

`ksoftirqd/n`用来处理像网卡这样数据泛滥的情况。

接收高数据率的网卡会大量产生中断，这些中断可能会中断`__do_softirq`的执行，
这些中断由于上一次`__do_softirq`已经被激活不会再执行软中断，但会重新激活`__softirq_pending`字段，

如果`do_softirq`不执行这些再次激活的，最坏的情况是，只有在下次时钟中断到来时执行。当然如果不空闲，在下一次中断时被处理。

如果此时`__do_softirq`恢复后一直执行这些pending的软中断，会造成用户进程一直执行。
所以`__do_softirq`限制了重新执行的次数，如果超过了，还有`__softirq_pending`则唤醒`ksoftirqd/n`内核线程执行，
内核线程具有较低的优先级，保证了用户进程能够有机会执行，空闲时，又保证了激活的软中断能被快速执行。

### tasklet

tasklet是建立在`HI_SOFTIRQ`和`TASKLET_IRQ`软中断之上的，这两个没有真正的区别，只是执行的优先级不用。

tasklet和高优先级taslet放在`tasklet_vec`和`tasklet_hi_vec`数组中，每个数组包含`NR_CPUS`个类型为`tasklet_head`的元素，每个元素都指向`task_struct`的链表。
> 注意32类软中断是每个CPU共享的，但tasklet链表是每个一CPU一个。
> 也就是说每个CPU只能执行自己的`tasklet`

`tasklet_struct`字段见p181，主要有`next` `state` `func` `data` `count`

比如驱动程序可以按如下方式使用tasklet:
1. 首先闯将`task_struct`类型的描述符，再用`tasklet_init`初始化它
2. 然后执行`tasklet_schedule`或者`tasklet_hi_schedule`，该函数主要做如下工作
    * 将该`tasklet_struct`对象插入`tasklet_vec`或者`tasklet_hi_vec`的链表中
    * 然后执行`raise_softirq_irqoff`（类似`raise_softirq`)激活`HI_SOFTIRQ`或者`TASKLET_SOFTIRQ`软中断

> 注意这里只说明功能性的操作，像是保护数据安全的措施没有再单独说明，比如锁的使用，或者中断的开关

`TASKLET_SOFTIRQ`或者`HI`执行对应的软中断函数`tasklet_action`或者`hi`版本，该函数主要做如下工作
1. 将`tasklet_vec[n]`或`hi_vec[n]`中的链表写入局部变量list，并将其链表头指针置空NULL
2. 然后依次执行`tasklet_struct`的链接即可
> 这里的问题在于，书中说保证多处理器同类型tasklet串行执行的有点问题啊，见红笔字
> 为`tasklet_vec[n]->lilst[0]`写入了`RUN`标志，我在其他CPU上执行的是自己的`tasklet_vec[n+k]`了根本访问不到这个标志啊？？
> 草，破案了，每个驱动程序模块在加载的时候就会创建`tasklet_struct`变量，之后只是插入到不同的CPU上


## || 中断处理程序总览（总结）

> 中断处理程序其实没有那么难，难的地方在于，书中只给出了代码过程和基本解释。没有从整体上说明代码的目标是什么，要求是什么。
> 这些必须要自己从代码中去反推，这很不好

`do_IRQ`就是包含整个上下半部的中断处理程序，伪代码如下：
> 这里直接把所有函数展开，方便考虑全局情况
```c
void do_IRQ(irq){
	irq_enter(){
		// 递增硬件中断计数器
		// 表示上半部开始
		current()->preempt_count->hardirq_count++;
	};
	__do_IRQ(irq){
		// 其他的忽略这里只讨论可能导致多重中断的情况
		// 执行ISR链表某个可以开中断的ISR
		sti;
		// 从这里开始可能被中断
		// 如果在这里被中断，新中断同样会执行do_IRQ也就是同样上下半部
		// 新上半部__do_IRQ由于`IRQ_INPROGEESS`标志会很快退出
		// 新下半部执行irq_exit()时，!in_interrupt()检测无法通过（旧irq_enter递增了硬件中断计数器）
		// 也直接退出，也就是说软中断不会在这种情况下执行，只会在只有一重中断时执行。
		ISR();
		cli;

	};
	irq_exit(){
		// 递减硬件中断计数器
		// 表示上半部结束
		current()->preempt_count->hardirq_count--;

		// 下半部
		if(!in_interrupt() && local_softirq_pending())
			do_softirq(){
				if(!in_interrupt()){
					// 其他，换栈，保存eflags等忽略
					__do_softirq(){
						local_bh_enable(){
							// 递增软中断计数器
							// 表示一个软中断已开始
							current()->preempt_count->softirq++;
						}

						// 开中断执行可延迟函数
						sti;
						// 从这里开始可能被中断
						// 如果在这里被中断，新中断同样会执行do_IRQ也就是同样上下半部
						// 此时新上半部照常执行
						// 当执行到下半部时，在irq_exit()中!in_interrupt同样无法通过
						// 此时又是因为软中断计数器被设置
						// 所以此时软中断无法被执行，保证了软中断在单颗CPU上的串行性
						// 所以无论如何在多重中断中软中断一定不会被执行
						// 只有单重中断时软中断才会被执行
						custom_softirq();
						cli;

						// 递减软中断计数器表示软中断结束
						current()->preempt_count->softirq--;
					}
				}
			};
	}
}
```
所以整个`do_IRQ`的设计目标就比较明了了。
对于上半部，就是要串行化执行，多CPU之间，单CPU上
下半部，同样要串行化，但只需保证单CPU的串行即可。除此之外，也不允许多重中断执行软中断，在ISR()处切入的多重中断如果还执行软中断，在软中断频繁的情况下（某些高数据率驱动）会导致用户进程被延迟（当然ISR能被中断的情况非常少）

## || 工作队列

工作队列和可延迟函数的主要区别则在于工作队列运行在进程上下文中，而不是中断上下文中。

对于中断处理程序而言，其在执行过程中是不能休眠（休眠就是挂到一个等待队列上，然后切换其他进程执行），也即不能切换进程。主要的原因在于，内核可能使用独立的于进程的4KB硬中断栈和软中断栈，这些栈是所有进程共用的，如果此时被切换到另一进程，另一进程又被中断了，那么其会覆盖调公用的硬件中断栈和软中断中的内容。

但运行在进程空间的工作队列可以。

### 工作队列涉及的数据结构
> 详情见p183

`workqueue_struct`工作队列描述符，该描述符中包含`NR_CPUS`个`cpu_workqueue_struct`

`cpu_workqueue_struct`中包含指向`work_struct`的链表头、工作线程等待队列、自旋锁等其他字段。

`work_struct`包含具体的工作函数，pending字段等其他字段，pending在该work被插入具体的工作队列时被设置。

### 工作队列函数

`creat_workqueue`创建新的工作队列，其返回`workqueue_struct`描述符的地址，同时创建NR_CPUS个工作线程，这些线程挂在`cpu_workqueue_struct`中的等待队列上。也可以使用`create_singlethread_workqueue`创建一个工作线程。

`queue_work`向某个工作队列中插入`work_struct`，如果该工作队列已经被插入即pending字段已经被设置直接退出，否则插入，然后唤醒`cpu_workqueue_struct`中等待队列上的内核线程执行工作队列。

> 同样，这里对于保证数据安全的操作全部忽略

工作线程一般处于睡眠状态，在被`queue_work`唤醒后会执行并清空`cpu_workqueue_struct[n]`的`work_struct`链表。比较有趣的是工作线程是可以执行阻塞操作的，此时其被切换，再次运行时可能又在其他CPU上运行了。

在插入工作队列后，插入者进程可能想等待工作全部执行完在操作，可以使用`flush_workqueue`函数，该函数会让调用者再对应工作队列所有插入函数执行完之前阻塞。

### 预定义工作队列

为少数需要延迟执行的函数单独建立工作队列和工作线程开销是非常大的，所以内核预定义了一些工作队列，内核开发者可以任意使用这些队列。

比如放在`keventd_wq`数组中的`events`队列，并且单独封装了一些操作函数。

这样虽然节约了资源，但工作队列中某个工作不应该长时间处于阻塞态，这会影响同链表中其他工作的执行。

## || 处理器间中断


## || 从中断和异常返回

返回时需要考虑以下几点，而不是直接执行`iret`
1. 检查是否是多重控制路径
    * 如果不是执行`resume_userspace`
    * 是，执行`resume_kernel`处理内核抢占相关内容（见第五章）

2. 是否有pending的进程切换请求
3. 是否有pending的信号
4. 是否是单步执行和虚拟8086模式

`current_thread_info()->flags`标志和`preempt_count`字段，标识了是否有这写待处理项。

> 具体汇编见p187

